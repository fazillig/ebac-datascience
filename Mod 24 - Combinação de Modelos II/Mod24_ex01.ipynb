{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f55a58-2926-446a-bd64-aaa8f0964b90",
   "metadata": {},
   "source": [
    "# Tarefa 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4daee4-effe-4dd5-8dbd-d8da106d6660",
   "metadata": {},
   "source": [
    "### 1. Cite 5 diferenças entre Random Forest e Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43042b3-988c-423b-a60b-c1bc9424eef5",
   "metadata": {},
   "source": [
    "<div style=\"background: #EEEEF4; padding: 15px 20px; border-radius: 5px; margin-top: 20px\">\n",
    "    <p style=\"font-size: 11px; color: #666; font-weight: bold\">Resposta</p>\n",
    "    <ol>\n",
    "        <li>Random Forest usa um conjunto de Árvores de Decisão. AdaBoost utiliza um conjunto de Stumps (Árvores de decisão com apenas 2 folhas e 1 nível de profundidade)</li>\n",
    "\n",
    "<li>Na Random Forest as árvores são independentes. No AdaBoost uma árvore influencia na seguinte</li>\n",
    "\n",
    "<li>As árvores da Random Forest pode ser calculadas em paralelo.</li>\n",
    "\n",
    "<li>Na Random Forest as resposta das árvores tem o mesmo peso. No AdaBoost as respostas tem pesos diferentes</li>\n",
    "\n",
    "<li>Random Forest usa amostragem aleatória de recursos para treinar cada árvore, enquanto AdaBoost ajusta os pesos para enfatizar aqueles que são mais importantes.</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01cd706-2dd5-42a1-8971-b2bd96a1abb5",
   "metadata": {},
   "source": [
    "### 2. Implemente um modelo AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67900d13-99d4-43b9-944a-cee49585dd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3e56be-83a1-40b4-90e0-7f2b4c93d673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666665"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "adab = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "scores = cross_val_score(adab, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afe18a-8caa-4aed-9dd4-c3ad0ed73410",
   "metadata": {},
   "source": [
    "### 3. Cite 4 Hyperparametros importantes no AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed71ed6-8963-4dce-b060-a9b2679a51f1",
   "metadata": {},
   "source": [
    "<div style=\"background: #EEEEF4; padding: 15px 20px; border-radius: 5px; margin-top: 20px\">\n",
    "    <p style=\"font-size: 11px; color: #666; font-weight: bold\">Resposta</p>\n",
    "    <ul>\n",
    "        <li><b>estimator</b>: Classificador base que será usado pelo AdaBoost. Por padrão o algoritmo utiliza uma Árvore de Decisão com profundidade máxima igual a 1</li>\n",
    "        <li><b>n_estimators</b>: Número máximo de classificadores.</li>\n",
    "        <li><b>learning_rate</b>: Peso aplicado a cada classificador em cada iteração de reforço. Uma taxa de aprendizado mais alta aumenta a contribuição de cada classificador.</li>\n",
    "        <li><b>random_state</b>: Controla a semente aleatória fornecida em cada estimador em cada iteração de reforço.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
